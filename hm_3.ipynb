{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Загрузка данных\n",
    "data = np.load('digitsMnist.npy', allow_pickle=True)\n",
    "\n",
    "# Разделение данных\n",
    "X_forTrain = data[0]\n",
    "Y_forTrain = data[1]\n",
    "X_forVal = data[2]\n",
    "Y_forVal = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3  Условная выборка цифр 3 и 8\n",
    "\n",
    "train_mask = (Y_forTrain == 3) | (Y_forTrain == 8)\n",
    "val_mask = (Y_forVal == 3) | (Y_forVal == 8)\n",
    "\n",
    "X_forTrain = X_forTrain[train_mask]\n",
    "Y_forTrain = Y_forTrain[train_mask]\n",
    "X_forVal = X_forVal[val_mask]\n",
    "Y_forVal = Y_forVal[val_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Переименование меток для бинарной классификации\n",
    "\n",
    "Y_forTrain = np.where(Y_forTrain == 3, 0, 1)\n",
    "Y_forVal = np.where(Y_forVal == 3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Нормализация данных\n",
    "\n",
    "X_forTrain = X_forTrain / 255.0\n",
    "X_forVal = X_forVal / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#6 Разбиение на обучающую и тестовую выборки\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_forTrain, Y_forTrain, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#7 Преобразование массивов в тензоры\n",
    "\n",
    "X_train_tensors = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensors = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_train_tensors = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_test_tensors = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "X_val_tensors = torch.tensor(X_forVal, dtype=torch.float32)\n",
    "Y_val_tensors = torch.tensor(Y_forVal, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9-11 Создание TensorDataset для обучающей, тестовой и валидационной выборок\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Объединяем входные данные и метки в TensorDataset\n",
    "trainDataset = TensorDataset(X_train_tensors, Y_train_tensors)\n",
    "testDataset = TensorDataset(X_test_tensors, Y_test_tensors)\n",
    "valDataset = TensorDataset(X_val_tensors, Y_val_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12-14  Создание DataLoader для батчей\n",
    " \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Размер батча (выберите оптимальный для вашей задачи, например, 64)\n",
    "batch_size = 64\n",
    "\n",
    "# Создаем DataLoader для обучающей, тестовой и валидационной выборок\n",
    "train_loader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testDataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(valDataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15 Создание класса нейронной сети\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # Входной слой: 784 нейрона, скрытый слой: 128 нейронов\n",
    "        self.fc2 = nn.Linear(128, 64)       # Скрытый слой: 64 нейрона\n",
    "        self.fc3 = nn.Linear(64, 2)         # Выходной слой: 2 класса (бинарная классификация)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)            # Преобразуем тензор в вектор\n",
    "        x = F.relu(self.fc1(x))            # Функция активации ReLU для первого слоя\n",
    "        x = F.relu(self.fc2(x))            # Функция активации ReLU для второго слоя\n",
    "        x = self.fc3(x)                    # Выходной слой (без активации)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16-19 Создание экземпляра сети, выбор оптимизатора и функции потерь\n",
    "\n",
    "# Создание экземпляра сети\n",
    "simplenet = SimpleNet()\n",
    "\n",
    "# Выбор оптимизатора Adam с шагом обучения lr=0.001\n",
    "optimizer = torch.optim.Adam(simplenet.parameters(), lr=0.001)\n",
    "\n",
    "# Выбор функции потерь: перекрестная энтропия\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.1559, Test Loss: 0.1476, Accuracy: 0.9499\n",
      "Epoch [2/10], Train Loss: 0.0782, Test Loss: 0.0692, Accuracy: 0.9762\n",
      "Epoch [3/10], Train Loss: 0.0471, Test Loss: 0.0416, Accuracy: 0.9875\n",
      "Epoch [4/10], Train Loss: 0.0274, Test Loss: 0.0326, Accuracy: 0.9900\n",
      "Epoch [5/10], Train Loss: 0.0163, Test Loss: 0.0342, Accuracy: 0.9900\n",
      "Epoch [6/10], Train Loss: 0.0125, Test Loss: 0.0305, Accuracy: 0.9917\n",
      "Epoch [7/10], Train Loss: 0.0075, Test Loss: 0.0415, Accuracy: 0.9900\n",
      "Epoch [8/10], Train Loss: 0.0055, Test Loss: 0.0433, Accuracy: 0.9912\n",
      "Epoch [9/10], Train Loss: 0.0066, Test Loss: 0.0494, Accuracy: 0.9896\n",
      "Epoch [10/10], Train Loss: 0.0060, Test Loss: 0.0349, Accuracy: 0.9921\n"
     ]
    }
   ],
   "source": [
    "#20-21  Обучение модели\n",
    "\n",
    "# Используем CPU для вычислений\n",
    "device = torch.device('cpu')\n",
    "simplenet.to(device)\n",
    "\n",
    "# Количество эпох\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    simplenet.train()  # Включаем режим обучения\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Обучение на батчах\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()               # Обнуляем градиенты\n",
    "        outputs = simplenet(X_batch)        # Прогон вперед\n",
    "        loss = criterion(outputs, Y_batch)  # Вычисляем функцию потерь\n",
    "        loss.backward()                     # Вычисляем градиенты\n",
    "        optimizer.step()                    # Обновляем параметры сети\n",
    "        \n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    # Оценка на тестовой выборке\n",
    "    simplenet.eval()  # Включаем режим оценки\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in test_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            outputs = simplenet(X_batch)\n",
    "            loss = criterion(outputs, Y_batch)\n",
    "            test_loss += loss.item() * X_batch.size(0)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == Y_batch).sum().item()\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, '\n",
    "          f'Test Loss: {test_loss:.4f}, '\n",
    "          f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0324, Validation Accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "#21 Оценка на валидационной выборке\n",
    "\n",
    "val_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, Y_batch in val_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        outputs = simplenet(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "        val_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == Y_batch).sum().item()\n",
    "\n",
    "val_loss /= len(val_loader.dataset)\n",
    "val_accuracy = correct / len(val_loader.dataset)\n",
    "\n",
    "print(f'Validation Loss: {val_loss:.4f}, '\n",
    "      f'Validation Accuracy: {val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"logs\", name=\"simple_net\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=logger\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | fc1       | Linear             | 100 K \n",
      "1 | fc2       | Linear             | 8.3 K \n",
      "2 | fc3       | Linear             | 130   \n",
      "3 | criterion | CrossEntropyLoss   | 0     \n",
      "4 | accuracy  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.435     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\study\\python\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 181/181 [00:01<00:00, 152.17it/s, loss=0.000797, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 181/181 [00:01<00:00, 150.42it/s, loss=0.000797, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNet()\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
